#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°†userå’Œassistantè§’è‰²çš„jsonlæ–‡ä»¶åˆå¹¶ä¸ºSFTæ•°æ®é›†æ ¼å¼
è¾“å…¥ï¼šä¸¤ä¸ªjsonlæ–‡ä»¶ï¼Œä¸€ä¸ªåŒ…å«userè§’è‰²ï¼Œä¸€ä¸ªåŒ…å«assistantè§’è‰²
è¾“å‡ºï¼šSFTæ•°æ®é›†æ ¼å¼çš„jsonlæ–‡ä»¶
"""

import json

def merge_to_sft_format(user_file_path, assistant_file_path, output_path):
    """
    å°†userå’Œassistantæ–‡ä»¶åˆå¹¶ä¸ºSFTæ ¼å¼
    
    Args:
        user_file_path: åŒ…å«userè§’è‰²çš„jsonlæ–‡ä»¶è·¯å¾„
        assistant_file_path: åŒ…å«assistantè§’è‰²çš„jsonlæ–‡ä»¶è·¯å¾„
        output_path: è¾“å‡ºSFTæ ¼å¼jsonlæ–‡ä»¶è·¯å¾„
    """
    
    # è¯»å–useræ–‡ä»¶
    with open(user_file_path, 'r', encoding='utf-8') as f_user:
        user_lines = f_user.readlines()
    
    # è¯»å–assistantæ–‡ä»¶
    with open(assistant_file_path, 'r', encoding='utf-8') as f_assistant:
        assistant_lines = f_assistant.readlines()
    
    # æ£€æŸ¥ä¸¤ä¸ªæ–‡ä»¶è¡Œæ•°æ˜¯å¦ä¸€è‡´
    if len(user_lines) != len(assistant_lines):
        raise ValueError(f"ä¸¤ä¸ªæ–‡ä»¶çš„è¡Œæ•°ä¸ä¸€è‡´: useræ–‡ä»¶æœ‰{len(user_lines)}è¡Œï¼Œassistantæ–‡ä»¶æœ‰{len(assistant_lines)}è¡Œ")
    
    # è½¬æ¢ä¸ºSFTæ ¼å¼
    sft_data = []
    
    for i, (user_line, assistant_line) in enumerate(zip(user_lines, assistant_lines)):
        try:
            # è§£æJSON
            user_data = json.loads(user_line.strip())
            assistant_data = json.loads(assistant_line.strip())
            
            # éªŒè¯roleå­—æ®µ
            if user_data.get('role') != 'user':
                print(f"è­¦å‘Šï¼šç¬¬{i+1}è¡Œuseræ–‡ä»¶çš„roleä¸æ˜¯'user'ï¼Œè€Œæ˜¯'{user_data.get('role')}'")
            
            if assistant_data.get('role') != 'assistant':
                print(f"è­¦å‘Šï¼šç¬¬{i+1}è¡Œassistantæ–‡ä»¶çš„roleä¸æ˜¯'assistant'ï¼Œè€Œæ˜¯'{assistant_data.get('role')}'")
            
            # åˆ›å»ºSFTæ ¼å¼çš„å¯¹è¯
            conversation = {
                "conversations": [
                    {
                        "role": "user",
                        "content": user_data['content']
                    },
                    {
                        "role": "assistant", 
                        "content": assistant_data['content']
                    }
                ]
            }
            
            sft_data.append(conversation)
            
        except json.JSONDecodeError as e:
            print(f"è­¦å‘Šï¼šç¬¬{i+1}è¡ŒJSONè§£æå¤±è´¥")
            print(f"Useræ–‡ä»¶: {user_line}")
            print(f"Assistantæ–‡ä»¶: {assistant_line}")
            print(f"é”™è¯¯: {e}")
            continue
    
    # å†™å…¥SFTæ ¼å¼æ–‡ä»¶
    with open(output_path, 'w', encoding='utf-8') as f_out:
        for conversation in sft_data:
            f_out.write(json.dumps(conversation, ensure_ascii=False) + '\n')
    
    print(f"âœ… SFTæ ¼å¼åˆå¹¶å®Œæˆï¼")
    print(f"ğŸ“ Useræ–‡ä»¶: {user_file_path}")
    print(f"ğŸ“ Assistantæ–‡ä»¶: {assistant_file_path}")
    print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_path}")
    print(f"ğŸ”¢ è½¬æ¢äº† {len(sft_data)} æ¡å¯¹è¯")
    
    return len(sft_data)

def preview_sft_sample(file_path, sample_index=0):
    """é¢„è§ˆSFTæ ¼å¼æ–‡ä»¶çš„ç¤ºä¾‹"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
            if sample_index < len(lines):
                sample = json.loads(lines[sample_index])
                print(f"\nğŸ“‹ SFTæ ¼å¼ç¤ºä¾‹ (ç¬¬{sample_index+1}è¡Œ):")
                print(f"å¯¹è¯è½®æ¬¡æ•°é‡: {len(sample['conversations'])}")
                for i, turn in enumerate(sample['conversations']):
                    print(f"  è½®æ¬¡ {i+1}: {turn['role']} - å†…å®¹é•¿åº¦ {len(turn['content'])} å­—ç¬¦")
                return sample
    except Exception as e:
        print(f"âŒ é¢„è§ˆå¤±è´¥: {e}")
    return None

def main():
    # æ–‡ä»¶è·¯å¾„
    user_file = "RLHF_time/dataset_test/demo_prompts.jsonl"
    assistant_file = "merged_output.jsonl"
    output_file = "sft_dataset.jsonl"
    
    try:
        # è½¬æ¢ä¸ºSFTæ ¼å¼
        count = merge_to_sft_format(user_file, assistant_file, output_file)
        
        # é¢„è§ˆç»“æœ
        if count > 0:
            preview_sft_sample(output_file, 0)
            
            # æ˜¾ç¤ºç¬¬ä¸€è¡Œçš„éƒ¨åˆ†å†…å®¹ä½œä¸ºç¤ºä¾‹
            print(f"\nğŸ“„ å†…å®¹é¢„è§ˆ (ç¬¬ä¸€è¡Œå¼€å¤´):")
            with open(output_file, 'r', encoding='utf-8') as f:
                first_line = f.readline().strip()
                data = json.loads(first_line)
                print(f"User: {data['conversations'][0]['content'][:100]}...")
                print(f"Assistant: {data['conversations'][1]['content'][:100]}...")
        
    except Exception as e:
        print(f"âŒ è½¬æ¢å¤±è´¥: {e}")

if __name__ == "__main__":
    main()