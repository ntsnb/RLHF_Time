# RLHF_timeé¡¹ç›®å¾®è°ƒè®­ç»ƒå™¨

è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„å¤§è¯­è¨€æ¨¡å‹ç›‘ç£å¾®è°ƒ(SFT)è®­ç»ƒå™¨ï¼Œæ”¯æŒQwenã€Llamaç­‰ä¸»æµæ¨¡å‹çš„å¾®è°ƒã€‚

## ğŸš€ ä¸»è¦ç‰¹æ€§

### è®­ç»ƒç­–ç•¥
- **å…¨é‡å¾®è°ƒ**: è®­ç»ƒæ‰€æœ‰æ¨¡å‹å‚æ•°
- **LoRAå‚æ•°é«˜æ•ˆå¾®è°ƒ**: å‡å°‘æ˜¾å­˜å ç”¨ï¼Œæ”¯æŒæ›´å¤§batch size
- **å†»ç»“å±‚å¾®è°ƒ**: å†»ç»“å‰Nå±‚ï¼Œåªè®­ç»ƒåé¢çš„å±‚

### æ ¸å¿ƒåŠŸèƒ½
- **è‡ªåŠ¨æ··åˆç²¾åº¦è®­ç»ƒ**: æ”¯æŒAMPåŠ é€Ÿè®­ç»ƒ
- **æ¢¯åº¦ç´¯ç§¯**: æ”¯æŒæ¢¯åº¦ç´¯ç§¯ä»¥æ¨¡æ‹Ÿæ›´å¤§batch size
- **å­¦ä¹ ç‡è°ƒåº¦**: æ”¯æŒçº¿æ€§ã€ä½™å¼¦ã€æ’å®šè°ƒåº¦ç­–ç•¥
- **æ—©åœæœºåˆ¶**: åŸºäºè¯„ä¼°æŒ‡æ ‡è‡ªåŠ¨åœæ­¢è®­ç»ƒ
- **æ£€æŸ¥ç‚¹ä¿å­˜**: æ”¯æŒå®šæœŸä¿å­˜è®­ç»ƒçŠ¶æ€

### è¯„ä¼°å’Œç›‘æ§
- **å®æ—¶è¯„ä¼°**: æ”¯æŒæŒ‰æ­¥æ•°æˆ–è½®æ•°è¯„ä¼°
- **è®­ç»ƒç›‘æ§**: è¯¦ç»†çš„è®­ç»ƒæ—¥å¿—å’Œè¿›åº¦æ˜¾ç¤º
- **å¯è§†åŒ–**: æ”¯æŒTensorBoardæ—¥å¿—è®°å½•

### æŸå¤±å‡½æ•°
- **SFTæŸå¤±**: æ ‡å‡†è¯­è¨€å»ºæ¨¡æŸå¤±
- **æˆå¯¹æŸå¤±**: ç”¨äºå¥–åŠ±æ¨¡å‹è®­ç»ƒ
- **ç­–ç•¥æŸå¤±**: ç”¨äºRLHF/PPOè®­ç»ƒ
- **ä»·å€¼æŸå¤±**: ä»·å€¼ç½‘ç»œè®­ç»ƒ
- **çŸ¥è¯†è’¸é¦æŸå¤±**: æ¨¡å‹è’¸é¦

## ğŸ“¦ å®‰è£…ä¾èµ–

```bash
# åŸºç¡€ä¾èµ–
pip install torch torchvision torchaudio
pip install transformers datasets
pip install modelscope

# è®­ç»ƒç›¸å…³
pip install tqdm numpy pandas
pip install tensorboard

# LoRAæ”¯æŒ (å¯é€‰)
pip install peft

# å…¶ä»–
pip install scipy scikit-learn
```

## ğŸ› ï¸ å¿«é€Ÿå¼€å§‹

### 1. åŸºç¡€ä½¿ç”¨

```python
from trainer import SFTrainer, TrainingConfig

# åˆ›å»ºé…ç½®
config = TrainingConfig(
    experiment_name="my_sft_experiment",
    model_name="Qwen/Qwen3-8B",  # æˆ–æœ¬åœ°æ¨¡å‹è·¯å¾„
    model_type="Qwen",
    train_file="data/train.jsonl",
    eval_file="data/eval.jsonl",
    batch_size=4,
    learning_rate=2e-5,
    num_train_epochs=3,
)

# åˆ›å»ºè®­ç»ƒå™¨
trainer = SFTrainer(config)

# å¼€å§‹è®­ç»ƒ
results = trainer.train()

# é¢„æµ‹
predictions = trainer.predict(["ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚"])
```

### 2. LoRAå¾®è°ƒ

```python
config = TrainingConfig(
    experiment_name="my_lora_experiment",
    model_name="Qwen/Qwen3-8B",
    model_type="Qwen",
    
    # LoRAé…ç½®
    use_lora=True,
    lora_rank=16,
    lora_alpha=32,
    lora_dropout=0.1,
    lora_target_modules=["q_proj", "v_proj", "k_proj", "o_proj"],
    
    # LoRAè®­ç»ƒå¯ä»¥ä½¿ç”¨æ›´å¤§çš„batch size
    batch_size=8,
    learning_rate=1e-4,
)
```

### 3. å†»ç»“å±‚å¾®è°ƒ

```python
config = TrainingConfig(
    experiment_name="my_frozen_experiment",
    model_name="Qwen/Qwen3-8B",
    
    # å†»ç»“å‰6å±‚
    freeze_layers=list(range(6)),
    
    batch_size=4,
    learning_rate=5e-5,
)
```

## ğŸ“Š æ•°æ®æ ¼å¼

### æ”¯æŒçš„æ•°æ®æ ¼å¼

1. **JSONLæ ¼å¼** (æ¨è)
```jsonl
{"prompt": "ç”¨æˆ·é—®é¢˜", "response": "æ¨¡å‹å›ç­”"}
{"prompt": "å¦ä¸€ä¸ªé—®é¢˜", "response": "å¦ä¸€ä¸ªå›ç­”"}
```

2. **JSONæ ¼å¼**
```json
{
  "data": [
    {"prompt": "é—®é¢˜1", "response": "å›ç­”1"},
    {"prompt": "é—®é¢˜2", "response": "å›ç­”2"}
  ]
}
```

3. **CSVæ ¼å¼**
```csv
prompt,response
"é—®é¢˜1","å›ç­”1"
"é—®é¢˜2","å›ç­”2"
```

### è‡ªå®šä¹‰æ¨¡æ¿

```python
config = TrainingConfig(
    prompt_template="è¯·å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š{prompt}",
    response_template="å›ç­”ï¼š{response}",
)
```

## âš™ï¸ é…ç½®å‚æ•°

### åŸºç¡€é…ç½®

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `experiment_name` | str | "sft_experiment" | å®éªŒåç§° |
| `model_name` | str | "Qwen/Qwen3-8B" | æ¨¡å‹åç§°æˆ–è·¯å¾„ |
| `model_type` | str | "Qwen" | æ¨¡å‹ç±»å‹ (Qwen/Llama) |
| `device` | str | None | è®¾å¤‡ç±»å‹ (cuda/cpu) |

### è®­ç»ƒå‚æ•°

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `batch_size` | int | 8 | æ‰¹æ¬¡å¤§å° |
| `learning_rate` | float | 2e-5 | å­¦ä¹ ç‡ |
| `num_train_epochs` | int | 3 | è®­ç»ƒè½®æ•° |
| `max_seq_length` | int | 2048 | æœ€å¤§åºåˆ—é•¿åº¦ |
| `gradient_accumulation_steps` | int | 1 | æ¢¯åº¦ç´¯ç§¯æ­¥æ•° |
| `warmup_steps_ratio` | float | 0.1 | warmupæ­¥æ•°å æ€»è®­ç»ƒæ­¥æ•°çš„æ¯”ä¾‹ |

### LoRAå‚æ•°

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `use_lora` | bool | False | æ˜¯å¦ä½¿ç”¨LoRA |
| `lora_rank` | int | 8 | LoRAç§© |
| `lora_alpha` | int | 32 | LoRAç¼©æ”¾å‚æ•° |
| `lora_dropout` | float | 0.1 | LoRA dropoutç‡ |
| `lora_target_modules` | List[str] | ["q_proj", "v_proj"] | ç›®æ ‡æ¨¡å— |

### ä¼˜åŒ–å™¨å‚æ•°

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `weight_decay` | float | 0.01 | æƒé‡è¡°å‡ |
| `adam_beta1` | float | 0.9 | Adamå‚æ•°Î²1 |
| `adam_beta2` | float | 0.999 | Adamå‚æ•°Î²2 |
| `adam_epsilon` | float | 1e-8 | Adamå‚æ•°Îµ |
| `max_grad_norm` | float | 1.0 | æœ€å¤§æ¢¯åº¦èŒƒæ•° |

## ğŸ”§ é«˜çº§ç”¨æ³•

### è‡ªå®šä¹‰æŸå¤±å‡½æ•°

```python
from loss import create_loss

# åˆ›å»ºè‡ªå®šä¹‰æŸå¤±çš„æ¨¡å‹
loss_fn = create_loss("sft", label_smoothing=0.1)
# æˆ–ä½¿ç”¨å…¶ä»–æŸå¤±ç±»å‹: "pairwise", "policy", "value", "kd"
```

### å›è°ƒå‡½æ•°

```python
def my_callback(trainer):
    print(f"è®­ç»ƒæ­¥éª¤: {trainer.global_step}")
    # è‡ªå®šä¹‰é€»è¾‘

trainer.callbacks.append(my_callback)
```

### æ¨¡å‹ä¿å­˜å’ŒåŠ è½½

```python
# ä¿å­˜æ¨¡å‹
trainer.model.save_pretrained("./checkpoints/my_model")

# åŠ è½½è®­ç»ƒå™¨çŠ¶æ€
trainer.load_from_checkpoint("./checkpoints/checkpoint-1000")
```

### è¯„ä¼°å’Œç”Ÿæˆ

```python
# è¯„ä¼°
eval_result = trainer.evaluate()
print(f"è¯„ä¼°ç»“æœ: {eval_result}")

# å•è½®å¯¹è¯
response = trainer.chat([
    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ã€‚"},
    {"role": "user", "content": "ä½ å¥½"}
])

# æ‰¹é‡ç”Ÿæˆ
prompts = ["é—®é¢˜1", "é—®é¢˜2", "é—®é¢˜3"]
responses = trainer.predict(prompts, max_new_tokens=512)
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
RLHF_time/
â”œâ”€â”€ trainer.py           # ä¸»è®­ç»ƒå™¨
â”œâ”€â”€ trainer_example.py   # ä½¿ç”¨ç¤ºä¾‹
â”œâ”€â”€ loss.py              # æŸå¤±å‡½æ•°
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ sft_dataset.py   # æ•°æ®é›†å¤„ç†
â”‚   â”œâ”€â”€ prompt_maker.py  # æç¤ºæ¨¡æ¿
â”‚   â””â”€â”€ ...
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ base_llm.py      # åŸºç¡€æ¨¡å‹ç±»
â”‚   â”œâ”€â”€ Qwen.py          # Qwenæ¨¡å‹å®ç°
â”‚   â””â”€â”€ Llama.py         # Llamaæ¨¡å‹å®ç°
â””â”€â”€ checkpoints/         # æ¨¡å‹æ£€æŸ¥ç‚¹
```

## ğŸ› å¸¸è§é—®é¢˜

### 1. æ˜¾å­˜ä¸è¶³
- ä½¿ç”¨LoRAå¾®è°ƒï¼š`use_lora=True`
- å‡å°batch_size
- å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼š`use_gradient_checkpointing=True`
- ä½¿ç”¨è‡ªåŠ¨æ··åˆç²¾åº¦ï¼š`use_amp=True`

### 2. è®­ç»ƒé€Ÿåº¦æ…¢
- ç¡®ä¿ä½¿ç”¨GPU
- å¯ç”¨è‡ªåŠ¨æ··åˆç²¾åº¦ï¼š`use_amp=True`
- é€‚å½“å¢å¤§batch_size
- ä½¿ç”¨å¤šGPUï¼ˆå¦‚æœå¯ç”¨ï¼‰

### 3. æ¨¡å‹ä¸æ”¶æ•›
- æ£€æŸ¥å­¦ä¹ ç‡æ˜¯å¦åˆé€‚
- è°ƒæ•´warmup_steps_ratio
- æ£€æŸ¥æ•°æ®è´¨é‡
- è°ƒæ•´æ­£åˆ™åŒ–å‚æ•°

### 4. å†…å­˜æ³„éœ²
- å®šæœŸè°ƒç”¨ï¼š`torch.cuda.empty_cache()`
- å‡å°åºåˆ—é•¿åº¦ï¼š`max_seq_length`
- å…³é—­æ¢¯åº¦æ£€æŸ¥ç‚¹

## ğŸ“š å‚è€ƒèµ„æ–™

- [Qwenæ¨¡å‹æ–‡æ¡£](https://huggingface.co/Qwen)
- [LoRAè®ºæ–‡](https://arxiv.org/abs/2106.09685)
- [PEFTåº“æ–‡æ¡£](https://huggingface.co/docs/peft)
- [Transformersåº“](https://huggingface.co/docs/transformers)

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestæ¥æ”¹è¿›è¿™ä¸ªé¡¹ç›®ï¼

## ğŸ“„ è®¸å¯è¯

MIT License